# Changelog - Data Logger Entwicklung

Diese Datei dokumentiert alle Ã„nderungen und Entwicklungsfortschritte am Data Logger fÃ¼r das Franka Cube Stacking Projekt.

## [2026-01-30] - âš¡ Dynamischer Task-Pool: Work-Stealing fÃ¼r optimale Parallelisierung

### ğŸ¯ Problem

Bei der bisherigen statischen Episode-Verteilung (`episodes_per_env = NUM_EPISODES // NUM_ENVS`) kam es zu **Leerlauf-Situationen**:

```
Beispiel: 50 Episoden auf 10 Environments = 5 pro Env

Env 0: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ fertig (5 Episoden)
Env 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ fertig (5 Episoden)
...
Env 8: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ fertig (5 Episoden)
Env 9: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ noch 2 offen   â† 9 Envs IDLE!
```

**Ursache**: Unterschiedliche Episode-Dauern durch:
- Verschiedene WÃ¼rfel-Positionen (lÃ¤ngere/kÃ¼rzere Wege)
- Fehlgeschlagene Episoden (Retry-Overhead)
- ZufÃ¤llige Controller-Varianz

### ğŸ’¡ LÃ¶sung: Dynamischer Task-Pool (Work-Stealing)

Statt fester Zuteilung: **Zentrale Warteschlange** â€“ wer fertig ist, holt sich die nÃ¤chste Episode.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         EPISODE-POOL (zentral)          â”‚
â”‚        remaining_episodes = 50          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚ Env 0 â”‚   â”‚ Env 1 â”‚   â”‚ Env 2 â”‚ ...
â”‚ holt  â”‚   â”‚ holt  â”‚   â”‚ holt  â”‚
â”‚ Ep.1  â”‚   â”‚ Ep.2  â”‚   â”‚ Ep.3  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚           â”‚           â”‚
    â–¼ fertig    â”‚           â”‚
 holt Ep.11     â–¼ fertig    â”‚
    â”‚        holt Ep.12     â–¼ fertig
    ...         ...      holt Ep.13
```

### âœ… Implementierung

#### Neue Variablen
```python
remaining_episodes_to_start = NUM_EPISODES  # Pool-GrÃ¶ÃŸe
episodes_in_progress = 0                     # Aktuell laufende
total_attempts = 0                           # ZÃ¤hler inkl. FehlschlÃ¤ge
MAX_TOTAL_ATTEMPTS = NUM_EPISODES * 3        # Sicherheitslimit
```

#### Kernlogik (nach Episode-Ende)
```python
# Episode abgeschlossen
episodes_in_progress -= 1

# NÃ¤chste Episode aus Pool holen
if remaining_episodes_to_start > 0 and total_successful < NUM_EPISODES:
    remaining_episodes_to_start -= 1
    episodes_in_progress += 1
    total_attempts += 1
    # â†’ Neue Episode starten
else:
    env_done[i] = True  # Env geht in Ruhestand
```

#### Fehlschlag-Kompensation
```python
# Bei fehlgeschlagener Episode: Pool nachfÃ¼llen
if not is_valid:
    if total_attempts < MAX_TOTAL_ATTEMPTS:
        remaining_episodes_to_start += 1  # â† Kompensation!
```

### ğŸ“Š Vorteile

| Aspekt | Statisch (alt) | Dynamisch (neu) |
|--------|----------------|-----------------|
| Idle-Zeit | Hoch (bis zu 90%) | Minimal |
| Auslastung | UngleichmÃ¤ÃŸig | Optimal |
| Fehlschlag-Handling | Feste Quote | Automatische Kompensation |
| Episode-Anzahl | Kann unterschreiten | Exakt garantiert* |

*Solange Erfolgsrate > 33% (bei 3x Retry-Limit)

### ğŸ”’ Garantien

1. **Exakt `NUM_EPISODES` erfolgreiche Episoden** (wenn mÃ¶glich)
2. **Keine Idle-Environments** bis Pool leer
3. **Keine Ãœberschreitung** der Ziel-Anzahl
4. **Abbruch-Sicherheit** bei zu vielen FehlschlÃ¤gen

### ğŸ“‹ GeÃ¤nderte Dateien

- `fcs_main_parallel.py`:
  - Zeile ~900: Task-Pool Variablen
  - Zeile ~930: Initiale Episode-Verteilung mit Pool
  - Zeile ~970: Hauptschleifen-Abbruchbedingung
  - Zeile ~1220: Work-Stealing Logik nach Episode-Ende
  - Zeile ~1170: Fehlschlag-Kompensation
  - Zeile ~1300: Erweiterte Abschluss-Statistik

### ğŸ“ Logging-Verbesserungen

```
INFO: Task-Pool initialisiert: 50 Episoden zu verteilen
INFO:   Max. Versuche bei FehlschlÃ¤gen: 150
INFO: Env 3: Neue Episode gestartet (verbleibend: 42, in Arbeit: 8, Versuche: 12/150)
INFO: Env 7: Fertig (6 erfolgreiche Episoden, keine weiteren verfÃ¼gbar)
```

---

## [2026-01-28] - ğŸ¤– Robot-Opacity: Roboter-freie Trainingsbilder

### ğŸ¯ Problem

Bei der Analyse der Trainingsbilder des Franka Cube Stack Datensatzes wurde festgestellt, dass der **Roboter in allen Bildern sichtbar** ist. Im Vergleich dazu zeigt der Referenz-Datensatz (`deformable_rope_sample`) **keine Roboter** in den Bildern.

**Warum ist das problematisch fÃ¼r das DINO World Model?**

1. **Verwirrung beim Lernen**: Das Modell soll lernen, wie sich **Objekte** (WÃ¼rfel) durch **Actions** bewegen. Wenn der Roboter sichtbar ist, muss das Modell zusÃ¤tzlich lernen:
   - Roboter-Bewegung zu ignorieren
   - Oder Roboter-Bewegung als Teil der Dynamik zu modellieren

2. **HÃ¶here KomplexitÃ¤t**: Der Roboter hat viele bewegliche Teile (7 Gelenke, Greifer), die das visuelle Signal dominieren kÃ¶nnen.

3. **Transfer-Problem**: Ein Modell, das mit sichtbarem Roboter trainiert wurde, generalisiert schlechter auf neue Roboter oder Szenen.

4. **Referenz-Datensatz**: Der `deformable_rope_sample` Datensatz zeigt, dass das DINO WM erfolgreich **ohne sichtbaren Roboter** trainiert werden kann.

### ğŸ’¡ LÃ¶sungsansÃ¤tze (Analyse)

#### Ansatz 1: WÃ¼rfel einfrieren + Roboter wegbewegen
**Idee**: Physik des WÃ¼rfels kurz einfrieren, Roboter aus dem Bildbereich bewegen, Bild aufnehmen.

**âŒ Probleme**:
- WÃ¼rfel wÃ¼rde beim "Unfreeze" fallen (Gravitation)
- Komplexe State-Management nÃ¶tig
- UnnatÃ¼rliche Physik-Artefakte mÃ¶glich
- ZeitaufwÃ¤ndig (Roboter muss sich bewegen)

**Bewertung**: Nicht praktikabel

#### Ansatz 2: Multi-Kamera Setup
**Idee**: Mehrere Kameras aus verschiedenen Winkeln, mindestens eine ohne Roboter-Sicht.

**âœ… Vorteile**:
- Mehr Perspektiven fÃ¼r robusteres Training
- Redundanz bei Verdeckungen
- Realistischere Daten

**âš ï¸ Nachteile**:
- Mehr Speicherplatz benÃ¶tigt
- Komplexere Kamera-Konfiguration
- Nicht garantiert, dass Roboter in allen Ansichten unsichtbar ist

**Bewertung**: Gute ErgÃ¤nzung, aber lÃ¶st das Kernproblem nicht vollstÃ¤ndig

#### Ansatz 3: Roboter transparent/unsichtbar machen âœ… IMPLEMENTIERT
**Idee**: Roboter wÃ¤hrend der Bildaufnahme visuell unsichtbar machen, Physik lÃ¤uft normal weiter.

**âœ… Vorteile**:
- Saubere Bilder ohne Roboter (wie Referenz-Datensatz)
- Keine Physik-Ã„nderungen nÃ¶tig
- Simulation lÃ¤uft unverÃ¤ndert
- Stufenlose Opacity (0-100%) fÃ¼r FlexibilitÃ¤t
- Minimaler Performance-Impact

**Technische Umsetzung**:
```
1. Vor Bildaufnahme: Roboter-Opacity auf konfigurierten Wert setzen
2. Render-Update (damit Opacity wirkt)
3. Bild aufnehmen
4. Roboter-Opacity auf 100% zurÃ¼cksetzen
5. Simulation lÃ¤uft weiter
```

**Bewertung**: Beste LÃ¶sung fÃ¼r Simulation

### âœ… Implementierung

#### Neue Config-Option (`config.yaml`)
```yaml
camera:
  robot_opacity_for_capture: 0.0    # 0.0 - 1.0 Range
                                    # 1.0 = Voll sichtbar (opak)
                                    # 0.5 = Halbtransparent (50%)
                                    # 0.0 = Komplett unsichtbar
```

#### Neue Funktion (`fcs_main_parallel.py`)
```python
def set_robot_opacity(robot, opacity: float = 1.0):
    """
    Setzt die OpazitÃ¤t des Roboters fÃ¼r Bildaufnahmen.
    
    Verwendet USD's UsdGeom.Imageable API:
    - opacity = 0.0: MakeInvisible() (schnellster Weg)
    - opacity = 1.0: MakeVisible() (Standard)
    - opacity 0-1:   DisplayOpacity auf allen Mesh-Prims
    
    Physik bleibt vollstÃ¤ndig aktiv - nur visuell transparent!
    """
```

#### Modifizierte Hauptschleife
```python
# Vor Bildaufnahme
if ROBOT_OPACITY_FOR_CAPTURE < 1.0:
    set_robot_opacity(env.franka, opacity=ROBOT_OPACITY_FOR_CAPTURE)
    shared_world.render()  # Opacity anwenden

# Bild aufnehmen
rgb = get_rgb(camera, env_idx=i)

# Nach Bildaufnahme
if ROBOT_OPACITY_FOR_CAPTURE < 1.0:
    set_robot_opacity(env.franka, opacity=1.0)
```

### ğŸ“Š Verwendungsszenarien

| `robot_opacity_for_capture` | Anwendungsfall |
|-----------------------------|----------------|
| `0.0` | Referenz-Datensatz Style (kein Roboter) - **Empfohlen fÃ¼r Training** |
| `0.2` | Debugging: Schwache Roboter-Spur sichtbar |
| `0.5` | Halbtransparent (Overlay-Effekt fÃ¼r Visualisierung) |
| `1.0` | Roboter voll sichtbar (realistisch, fÃ¼r Real2Sim) |

### ğŸ”§ Technische Details

**USD API verwendet**:
- `UsdGeom.Imageable.MakeInvisible()` - FÃ¼r opacity=0
- `UsdGeom.Imageable.MakeVisible()` - FÃ¼r opacity=1
- `UsdGeom.Gprim.GetDisplayOpacityAttr()` - FÃ¼r 0 < opacity < 1

**Rekursive Anwendung**: Die Opacity wird auf alle Child-Prims des Roboters angewendet (Gelenke, Links, Meshes).

**Performance**: 
- `MakeInvisible()/MakeVisible()` sind sehr schnell
- DisplayOpacity erfordert Traversierung aller Mesh-Prims (etwas langsamer)
- Ein zusÃ¤tzlicher `render()` Call pro Bildaufnahme

### ğŸ“ NÃ¤chste Schritte

- [ ] Testen mit verschiedenen Opacity-Werten
- [ ] Vergleich Trainings-Performance: Mit vs. ohne Roboter
- [ ] Optional: Multi-Kamera Setup als ErgÃ¤nzung
- [ ] Dokumentation der optimalen Einstellungen

---

## [2026-01-25] - ğŸ‰ DURCHBRUCH: Erstes erfolgreiches Training!

### ğŸ¯ Problem

Die ursprÃ¼nglichen Controller-Einstellungen fÃ¼hrten zu **~950 Steps pro Episode** (bei 2 WÃ¼rfeln), was zu:
- Riesigen DatensÃ¤tzen
- Langen Trainingszeiten
- SpeicherÃ¼berlauf (Segmentation Faults)
- Keinem erfolgreichen Training

### âœ… LÃ¶sung: Aggressive dt-Optimierung

Durch drastische ErhÃ¶hung der Zeitschritte (dt) wurde die Episode-LÃ¤nge massiv reduziert:

**Alte Einstellungen (DEFAULT):**
```yaml
air_dt: 0.008 - 0.08
critical_dt: 0.005 - 0.0025
wait_dt: 1.0
grip_dt: 0.1
release_dt: 1.0
# â†’ ~950 Steps/Episode (2 WÃ¼rfel)
```

**Neue optimierte Einstellungen:**
```yaml
air_dt: 1.0           # 125x schneller!
critical_dt: 0.015    # 3-6x schneller
wait_dt: 1.0          # unverÃ¤ndert
grip_dt: 0.2          # 2x schneller
release_dt: 0.2       # 5x schneller
# â†’ ~150 Steps/Episode (1 WÃ¼rfel)
```

### ğŸ“Š Ergebnis

| Metrik | Vorher | Nachher | Verbesserung |
|--------|--------|---------|-------------|
| Steps/Episode (2 WÃ¼rfel) | ~950 | ~300 | **68% weniger** |
| Steps/Episode (1 WÃ¼rfel) | ~475 | ~150 | **68% weniger** |
| Training | âŒ Fehlgeschlagen | âœ… Halbwegs erfolgreich | **Erster Erfolg!** |
| DatensatzgrÃ¶ÃŸe | Riesig | Handhabbar | ~3x kleiner |

### âš ï¸ Bekannte Probleme

- Gelegentliche **Segmentation Faults** beim Training (vermutlich Datensatz-Format)
- QualitÃ¤t der Ergebnisse noch zu evaluieren
- MÃ¶glicherweise weitere Komprimierung nÃ¶tig

### ğŸ”§ Config-Ã„nderungen

```yaml
# config.yaml - Controller Section
controller:
  trajectory_resolution: 1.0
  air_speed_multiplier: 1.0
  height_adaptive_speed: False
  critical_height_threshold: 0.1
  critical_speed_factor: 0.5
  
  # NEUE OPTIMIERTE WERTE:
  air_dt: 1.0
  critical_dt: 0.015
  wait_dt: 1.0
  grip_dt: 0.2
  release_dt: 0.2

cubes:
  count: 1              # Reduziert fÃ¼r erstes Training
```

### ğŸ“ NÃ¤chste Schritte

- [ ] Evaluierung der Trainings-QualitÃ¤t
- [ ] Debugging des Segmentation Fault
- [ ] Testen mit 2 WÃ¼rfeln
- [ ] Weitere Datensatz-Komprimierung falls nÃ¶tig

---

## [2026-01-18] - CSV Episode Logger: Transponiertes Format + get_rgb() Funktion

### ğŸ¯ Ziel

HinzufÃ¼gen einer **fortlaufenden CSV-Logging-FunktionalitÃ¤t** zur Episode-Nachverfolgung mit:
- Eintrag pro Phase pro Episode (transponiert)
- Controller-Parameter pro Episode
- Trajektorie-Daten (Wegpunkte, Zeit, Modifikatoren)
- Validierungsstatus
- Ausgelagerte RGB-Extraktion in separate Funktion

### âœ… Neue Datei: `csv_episode_logger.py`

**Klasse: `CSVEpisodeLogger`**
```python
class CSVEpisodeLogger:
    PHASES = [
        "GRIP_OPEN", "MOVE_DOWN_CRITICAL", "GRIP_CLOSE", "MOVE_UP",
        "MOVE_TO_STACK", "MOVE_DOWN_CRITICAL_STK", "WAIT", 
        "GRIP_OPEN_STK", "MOVE_UP_STK", "MOVE_AWAY"
    ]
    
    def __init__(self, output_dir, filename="episode_tracking.csv")
    def log_episode(episode_id, controller_params, phase_data, 
                    total_timesteps, total_time, validation_success, notes)
```

### ğŸ“ CSV-Format (Transponiert)

**Header-Spalten:**
```
Episode ID | Phase | Phase Name | Datum | Zeit | trajectory_resolution | 
air_speed_multiplier | height_adaptive_speed | critical_height_threshold | 
critical_speed_factor | Gesamte Timesteps | Gesamtzeit (s) | 
Wegpunkte | Zeit (s) | Modifikator | Validierung erfolgreich | Notizen
```

**Beispiel-Zeilen (Episode 1 mit 10 Phasen = 10 Zeilen):**
```
1;0;GRIP_OPEN;18.01.2026;14:40:25;1,0;4,0;JA;0,05;0,8;483;8,05;42;0,7;1,0;âœ“ JA;Seed: 12345, Env: 0
1;1;MOVE_DOWN_CRITICAL;18.01.2026;14:40:25;1,0;4,0;JA;0,05;0,8;483;8,05;55;0,92;1,0;âœ“ JA;Seed: 12345, Env: 0
1;2;GRIP_CLOSE;18.01.2026;14:40:25;1,0;4,0;JA;0,05;0,8;483;8,05;38;0,63;1,0;âœ“ JA;Seed: 12345, Env: 0
...
```

### âœ… Vorteile des transponierten Formats

| Aspekt | Nicht-transponiert | Transponiert |
|--------|-------------------|--------------|
| Spalten pro Zeile | 47 (zu viele) | 17 (Ã¼bersichtlich) |
| Zeilen pro Episode | 1 | 10 |
| Phase-Filterung | âŒ Schwierig | âœ… `grep MOVE_DOWN` |
| Phase-Vergleiche | âŒ Komplex | âœ… Trivial (Zeile zu Zeile) |
| Excel-Ãœbersichtlichkeit | âŒ Schwer lesbar | âœ… Gut lesbar |
| Pivot-Tabellen | âŒ Viele Spalten | âœ… Einfach |

### âœ… Integration in `fcs_main_parallel.py`

#### 1. CSV Logger Initialisierung (nach Datenlogger-Setup)
```python
csv_logger = CSVEpisodeLogger(
    output_dir=str(logger.dataset_path),
    filename="episode_tracking.csv"
)
log.info(f"CSV Episode Logger initialisiert: {csv_logger.filepath}")
```

#### 2. Erfolgreiche Episode-Logging
```python
controller_params = {
    "trajectory_resolution": TRAJECTORY_RESOLUTION,
    "air_speed_multiplier": AIR_SPEED_MULTIPLIER,
    "height_adaptive_speed": HEIGHT_ADAPTIVE_SPEED,
    "critical_height_threshold": CRITICAL_HEIGHT_THRESHOLD,
    "critical_speed_factor": CRITICAL_SPEED_FACTOR,
}

csv_logger.log_episode(
    episode_id=total_successful,
    controller_params=controller_params,
    phase_data=phase_data,
    total_timesteps=step_counts[i],
    total_time=step_counts[i] * (1.0 / 60.0),
    validation_success=True,
    notes=f"Seed: {seeds[i]}, Env: {i}",
)
```

#### 3. Fehlgeschlagene Episode-Logging
```python
csv_logger.log_episode(
    episode_id=f"FAILED_{total_episodes}",
    controller_params=controller_params,
    phase_data={},
    total_timesteps=step_counts[i],
    total_time=step_counts[i] * (1.0 / 60.0),
    validation_success=False,
    notes=f"Seed: {seeds[i]}, Env: {i}, Grund: {reason}",
)
```

### âœ… Neue Hilfsfunktion: `get_rgb(camera, env_idx)`

**Zweck:** Ausgelagerte RGB-Bildextraktion mit automatischer Format-Konvertierung

**FunktionalitÃ¤t:**
```python
def get_rgb(camera, env_idx: int = 0) -> np.ndarray:
    """
    Extrahiert RGB-Bild aus Kamera-Feed mit automatischer Format-Konvertierung.
    
    Handles:
    - âŒ continue â†’ âœ… return None (keine Syntaxfehler mehr)
    - Automatische Shape-Konvertierung (1D, 2D, 3D)
    - Automatische Dtype-Konvertierung zu uint8
    - Guard-Clauses statt verschachtelte if-Statements
    
    Returns:
        np.ndarray: (H, W, 3) uint8 oder None bei Fehler
    """
```

**Vor der Refaktorierung:**
- ~60 Zeilen inline-Code in der Hauptschleife
- Mehrere `continue` Statements (Syntaxfehler in nicht-Loop-Kontext)
- Schwer zu lesen und zu warten

**Nach der Refaktorierung:**
- Separate `get_rgb()` Funktion (~70 Zeilen, aber sauberer)
- `if rgb is None: continue` in der Schleife
- Klar strukturierte Guard-Clauses

### ğŸ”§ Technische Ã„nderungen

#### 1. CSV-Format Details
- **Trennzeichen**: Semikolon (`;`)
- **Encoding**: UTF-8 mit BOM (Excel-kompatibel)
- **Dezimaltrennzeichen**: Komma (`,`) - deutsches Format
- **Datumsformat**: TT.MM.YYYY
- **Zeitformat**: HH:MM:SS
- **Boolesche Werte**: "JA" / "NEIN"
- **Validierungsstatus**: "âœ“ JA" / "âœ— NEIN"

#### 2. Controller-Parameter aus globalen Konstanten
**Fix fÃ¼r AttributeError:**
```python
# âŒ Alt (wirft AttributeError)
controller_params = {
    "trajectory_resolution": controller.trajectory_resolution,  # â† nicht vorhanden
    ...
}

# âœ… Neu (verwendet globale Konstanten)
controller_params = {
    "trajectory_resolution": TRAJECTORY_RESOLUTION,  # Aus Config
    "air_speed_multiplier": AIR_SPEED_MULTIPLIER,
    ...
}
```

**Grund:** `StackingController_JW` speichert Parameter nicht als Attribute. Die Parameter sind bereits als globale Konstanten aus der Config verfÃ¼gbar und alle Episoden verwenden dieselben Parameter.

#### 3. Phase-Daten Berechnung
```python
phase_data = {}
if len(episode_data[i]["observations"]) > 0:
    total_ep_steps = len(episode_data[i]["observations"])
    steps_per_phase = total_ep_steps // 10
    for phase_idx in range(10):
        phase_data[phase_idx] = {
            "waypoints": steps_per_phase,
            "time": steps_per_phase * (1.0 / 60.0),  # @ 60Hz
            "modifier": 1.0,
        }
```

**Hinweis:** Dies ist eine vereinfachte Verteilung. Die echten Controller-Phase-Daten kÃ¶nnten spÃ¤ter durch genaue Tracking verfeinert werden.

### ğŸ“ Output-Struktur

```
2026_01_18_1418_fcs_dset/
â”œâ”€â”€ episode_tracking.csv        # NEU: Alle Episode-Metadaten
â”œâ”€â”€ cameras/
â”‚   â”œâ”€â”€ intrinsic.npy
â”‚   â””â”€â”€ extrinsic.npy
â”œâ”€â”€ failed_seeds.txt
â””â”€â”€ 000000/
    â”œâ”€â”€ 000.h5
    â”œâ”€â”€ 001.h5
    â””â”€â”€ ...
```

### ğŸ› Fehlerbehebungen in diesem Update

1. âœ… **`continue` auÃŸerhalb Loop**: `get_rgb()` benutzt `return None`
2. âœ… **AttributeError bei Controller-Parametern**: Globale Konstanten statt Attribute
3. âœ… **CSV zu breit**: Transponiertes Format (17 statt 47 Spalten)
4. âœ… **Fehlende openpyxl**: CSV statt Excel (keine AbhÃ¤ngigkeiten)

### âœ… Validierung

- âœ… CSV wird nach jeder Episode geschrieben
- âœ… Erfolgreiche Episodes: grÃ¼ner Hintergrund (âœ“ JA)
- âœ… Fehlgeschlagene Episodes: roter Hintergrund (âœ— NEIN)
- âœ… Datei wird fortlaufend aktualisiert
- âœ… Excel/LibreOffice Ã¶ffnet CSV korrekt mit Semikolon-Trennzeichen

### ğŸ“ Verwendung in Excel

1. **Ã–ffnen**: CSV direkt mit Excel Ã¶ffnen
2. **Format**: Trennzeichen: Semikolon (`;`)
3. **Encoding**: UTF-8
4. **Filterung**: Spalte "Phase Name" um nur bestimmte Phasen zu sehen
5. **Pivot**: "Episode ID" Ã— "Phase Name" fÃ¼r Matrix-Ansicht

### ğŸ”„ NÃ¤chste Schritte (Optional)

- [ ] Echte Phase-Daten aus Controller tracking statt Vereinfachung
- [ ] Validierungsmetadaten (z.B. HÃ¶henÃ¼ber/unterschreitungen)
- [ ] Performance-Metriken (z.B. durchschnittliche Phasen-Dauer)
- [ ] Grafische Darstellung aus CSV (matplotlib, plotly)

---

## [2026-01-18] - MinDataLogger: Timestep-basierte H5-Dateien + Globale Dateien

### ğŸ¯ Ziel

Anpassung des MinDataLoggers auf das exakte Format des `deformable_rop_sample` Datensatzes:
- **Eine H5-Datei pro Timestep** (000.h5, 001.h5, ...) statt einer H5 pro Episode
- **`actions.pth` und `states.pth`** im Datensatz-Hauptordner
- **`property_params.pkl`** in jedem Episoden-Ordner

### âœ… Neue Dateien im Output

**Datensatz-Ebene:**
```
dataset/
â”œâ”€â”€ actions.pth            # (N_episodes, T_max, 6) float32
â”œâ”€â”€ states.pth             # (N_episodes, T_max, N_cubes*4) float32
â”œâ”€â”€ cameras/
â”‚   â”œâ”€â”€ intrinsic.npy
â”‚   â””â”€â”€ extrinsic.npy
```

**Episoden-Ebene:**
```
000000/
â”œâ”€â”€ 000.h5                 # Timestep 0
â”œâ”€â”€ 001.h5                 # Timestep 1
â”œâ”€â”€ 002.h5                 # Timestep 2
â”œâ”€â”€ ...
â”œâ”€â”€ obses.pth              # (T, H, W, 3) float32
â”œâ”€â”€ property_params.pkl    # Physik-Parameter
â”œâ”€â”€ first.png
â””â”€â”€ last.png
```

[... Rest des Changelogs bleibt gleich ...]

### ğŸ¯ Ziel

Anpassung des MinDataLoggers auf das exakte Format des `deformable_rop_sample` Datensatzes:
- **Eine H5-Datei pro Timestep** (000.h5, 001.h5, ...) statt einer H5 pro Episode
- **`actions.pth` und `states.pth`** im Datensatz-Hauptordner
- **`property_params.pkl`** in jedem Episoden-Ordner

### âœ… Neue Dateien im Output

**Datensatz-Ebene:**
```
dataset/
â”œâ”€â”€ actions.pth            # (N_episodes, T_max, 6) float32
â”œâ”€â”€ states.pth             # (N_episodes, T_max, N_cubes*4) float32
â”œâ”€â”€ cameras/
â”‚   â”œâ”€â”€ intrinsic.npy
â”‚   â””â”€â”€ extrinsic.npy
```

**Episoden-Ebene:**
```
000000/
â”œâ”€â”€ 000.h5                 # Timestep 0
â”œâ”€â”€ 001.h5                 # Timestep 1
â”œâ”€â”€ 002.h5                 # Timestep 2
â”œâ”€â”€ ...
â”œâ”€â”€ obses.pth              # (T, H, W, 3) float32
â”œâ”€â”€ property_params.pkl    # Physik-Parameter
â”œâ”€â”€ first.png
â””â”€â”€ last.png
```

### âœ… Ã„nderungen in `min_data_logger.py`

#### 1. Neue Imports
```python
import pickle
from typing import Dict, Any
```

#### 2. Neue Klassenattribute
```python
# Globale Listen fÃ¼r states.pth und actions.pth
self.all_actions: List[List[np.ndarray]] = []
self.all_states: List[List[np.ndarray]] = []
```

#### 3. GeÃ¤nderte `start_episode()`
```python
self.current_episode = {
    ...
    "actions_list": [],    # NEU: Actions fÃ¼r globale Datei
    "states_list": [],     # NEU: States fÃ¼r globale Datei
}
```

#### 4. GeÃ¤nderte `log_step()`
- **H5-Datei pro Timestep**: Speichert sofort `{timestep:03d}.h5`
- **Sammelt Actions**: `ep["actions_list"].append(action.copy())`
- **Sammelt States**: WÃ¼rfel-Positionen als `(N*4,)` Vektor (wie deformable Format)

```python
# .h5 Datei speichern (000.h5, 001.h5, etc.)
h5_path = ep["folder"] / f"{timestep:03d}.h5"
save_h5(h5_path, timestep_data)

# FÃ¼r globale Dateien
ep["actions_list"].append(action.copy())
state_with_vel = np.concatenate([positions[0], np.zeros((N, 1))], axis=1)
ep["states_list"].append(state_with_vel.flatten())
```

#### 5. GeÃ¤nderte `end_episode(property_params=None)`
- **Neuer Parameter**: `property_params` (optional, sonst Standard-Werte)
- **Speichert `property_params.pkl`**:
  ```python
  property_params = {
      "n_cubes": self.n_cubes,
      "cube_size": ...,
      "cube_mass": ...,
      "friction": ...,
  }
  with open(property_path, "wb") as f:
      pickle.dump(property_params, f)
  ```
- **ÃœbertrÃ¤gt Episode-Daten** in globale Listen:
  ```python
  self.all_actions.append(ep["actions_list"])
  self.all_states.append(ep["states_list"])
  ```

#### 6. Neue Methode `save_global_data()`
Speichert am Ende alle gesammelten Daten als globale Tensoren:

```python
def save_global_data(self):
    """
    Speichert globale actions.pth und states.pth fÃ¼r alle Episoden.
    
    Format:
        actions.pth: (N_episodes, T_max, action_dim) float32
        states.pth: (N_episodes, T_max, state_dim) float32
    """
    # Padding auf T_max fÃ¼r alle Episoden
    T_max = max(len(ep) for ep in self.all_actions)
    
    actions_array = np.zeros((N_episodes, T_max, action_dim), dtype=np.float32)
    states_array = np.zeros((N_episodes, T_max, state_dim), dtype=np.float32)
    
    # Daten einfÃ¼gen
    for ep_idx, (ep_actions, ep_states) in enumerate(zip(...)):
        T = len(ep_actions)
        actions_array[ep_idx, :T, :] = np.array(ep_actions)
        states_array[ep_idx, :T, :] = np.array(ep_states)
    
    torch.save(torch.from_numpy(actions_array), "actions.pth")
    torch.save(torch.from_numpy(states_array), "states.pth")
```

### ğŸ“ H5-Datei-Struktur (pro Timestep)

```python
000.h5
â”œâ”€â”€ action: (6,) float64         # [prev_ee_pos, current_ee_pos]
â”œâ”€â”€ eef_states: (1, 14) float64  # [pos, pos, quat, quat]
â”œâ”€â”€ positions: (1, N, 3) float32 # WÃ¼rfel-Positionen
â”œâ”€â”€ info/
â”‚   â”œâ”€â”€ n_cams: 1
â”‚   â”œâ”€â”€ timestamp: 1
â”‚   â””â”€â”€ n_particles: N
â””â”€â”€ observations/
    â”œâ”€â”€ color/cam_0: (1, H, W, 3)
    â””â”€â”€ depth/cam_0: (1, H, W) uint16
```

### ğŸ”„ Verwendung

```python
logger = MinDataLogger(config)

# Datensammlung
for episode in range(num_episodes):
    logger.start_episode()
    for step in range(steps):
        logger.log_step(rgb, depth, ee_pos, ee_quat, cube_positions)
    logger.end_episode()  # Speichert property_params.pkl

# Am Ende: globale Dateien speichern
logger.save_global_data()  # Speichert actions.pth und states.pth
logger.save_camera_calibration()
```

### ğŸ“Š Vergleich mit deformable_rop_sample

| Feature | deformable_rop_sample | MinDataLogger | Status |
|---------|----------------------|---------------|--------|
| H5 pro Timestep | âœ… 00.h5, 01.h5, ... | âœ… 000.h5, 001.h5, ... | âœ… Kompatibel |
| actions.pth | âœ… (N, T, action_dim) | âœ… (N, T, 6) | âœ… Kompatibel |
| states.pth | âœ… (N, T, n_particles, 4) | âœ… (N, T, N_cubes*4) | âœ… Kompatibel |
| property_params.pkl | âœ… Pro Episode | âœ… Pro Episode | âœ… Kompatibel |
| obses.pth | âœ… (T, H, W, 3) | âœ… (T, H, W, 3) | âœ… Kompatibel |

---

## [2026-01-17] - MinDataLogger: Minimale Version im data.py Format

### ğŸ¯ Ziel

Erstellung eines minimalen Data Loggers (`min_data_logger.py`), der:
- Nur den `ee_pos` Action-Mode (6D) unterstÃ¼tzt
- Daten exakt im Format von `dino_wm/env/deformable_env/src/sim/data_gen/data.py` speichert
- PNG-Speicherung beibehÃ¤lt
- Alle unnÃ¶tigen Funktionen entfernt (~500 â†’ ~180 Zeilen)

### âœ… Neue Datei: `min_data_logger.py`

**Kernfunktionen (aus data.py Ã¼bernommen):**
```python
def process_imgs(imgs_list):
    """Verarbeitet Bilder: RGB BGR->RGB, Depth -> uint16 (mm)"""
    
def save_h5(filename, data):
    """Speichert H5 mit verschachtelter Struktur wie data.py"""
```

**Klasse: `MinDataLogger`**
```python
class MinDataLogger:
    def __init__(self, config, config_path, action_mode, dt)  # action_mode/dt ignoriert
    def set_camera_calibration(intrinsic, extrinsic)
    def save_camera_calibration()
    def start_episode(episode_id)
    def log_step(rgb_image, depth_image, ee_pos, ee_quat, cube_positions)
    def end_episode()
    def discard_episode()
```

### ğŸ“ Output-Format (identisch zu data.py)

```
dataset/
â”œâ”€â”€ cameras/
â”‚   â”œâ”€â”€ intrinsic.npy      # (4, 4) float64
â”‚   â””â”€â”€ extrinsic.npy      # (4, 4, 4) float64
â””â”€â”€ 000000/                 # Episode
    â”œâ”€â”€ 00.h5              # Eine H5-Datei pro Episode
    â”‚   â”œâ”€â”€ action         # (6,) float64 - [x_start, y_start, z_start, x_end, y_end, z_end]
    â”‚   â”œâ”€â”€ eef_states     # (T, 14) float64
    â”‚   â”œâ”€â”€ positions      # (T, N, 3) float32
    â”‚   â”œâ”€â”€ info/
    â”‚   â”‚   â”œâ”€â”€ n_cams     # 1
    â”‚   â”‚   â”œâ”€â”€ timestamp  # T
    â”‚   â”‚   â””â”€â”€ n_particles# N (Anzahl WÃ¼rfel)
    â”‚   â””â”€â”€ observations/
    â”‚       â”œâ”€â”€ color/cam_0  # (T, H, W, 3) - BGR->RGB konvertiert
    â”‚       â””â”€â”€ depth/cam_0  # (T, H, W) uint16 - Millimeter
    â”œâ”€â”€ first.png          # Erstes Frame
    â””â”€â”€ last.png           # Letztes Frame
```

### âŒ Entfernte Features (gegenÃ¼ber FrankaDataLogger)

| Feature | Status |
|---------|--------|
| `action_mode="delta_pose"` | âŒ Entfernt |
| `action_mode="velocity"` | âŒ Entfernt |
| `action_interval` (mehrere H5 pro Episode) | âŒ Entfernt |
| `obses.pth` Speicherung | âŒ Entfernt |
| Quaternion-zu-Yaw Konvertierung | âŒ Entfernt |
| Velocity-Berechnungen | âŒ Entfernt |
| Disk-Space Checks | âŒ Entfernt |
| Detailliertes Logging | âŒ Reduziert |

### âœ… Beibehaltene Features

| Feature | Status |
|---------|--------|
| `ee_pos` Action (6D) | âœ… Einziger Modus |
| PNG-Speicherung (first.png, last.png) | âœ… Beibehalten |
| Kamera-Kalibrierung | âœ… Beibehalten |
| H5-Format | âœ… Wie data.py |
| Config aus YAML | âœ… Beibehalten |

### ğŸ”„ Verwendung in fcs_main_parallel.py

**Drop-in Ersatz** - nur Import Ã¤ndern:

```python
# Alt:
from data_logger import FrankaDataLogger, get_franka_state, get_franka_action

# Neu:
from min_data_logger import MinDataLogger as FrankaDataLogger
```

**API ist identisch:**
- `FrankaDataLogger(config, action_mode, dt)` â†’ action_mode/dt werden ignoriert
- `logger.object_name` â†’ vorhanden fÃ¼r KompatibilitÃ¤t
- `logger.dataset_path` â†’ vorhanden
- Alle Methoden identisch

### ğŸ“Š Vergleich: FrankaDataLogger vs MinDataLogger

| Aspekt | FrankaDataLogger | MinDataLogger |
|--------|------------------|---------------|
| Zeilen Code | ~800 | ~180 |
| Action-Modi | 3 (delta_pose, velocity, ee_pos) | 1 (ee_pos) |
| H5 pro Episode | Mehrere (action_interval) | Eine (00.h5) |
| obses.pth | âœ… Ja | âŒ Nein |
| Datenformat | Rope-kompatibel | data.py-kompatibel |
| PNG-Output | âŒ Nein | âœ… Ja (first/last) |

### ğŸ“ Hinweise

- **Beide Logger existieren parallel** - wÃ¤hle nach Bedarf
- `FrankaDataLogger` fÃ¼r vollstÃ¤ndige Rope-KompatibilitÃ¤t mit allen Features
- `MinDataLogger` fÃ¼r minimales data.py-kompatibles Format

---

## [2026-01-14] - Action Interval: Frame-Aggregation wie im Rope-Format

### âœ… Neuer Parameter: `action_interval`

Wie im Rope-Format kÃ¶nnen jetzt mehrere Frames zu einer Action zusammengefasst werden.
Der Parameter `action_interval` in `config.yaml` steuert dies zentral.

**Konfiguration (config.yaml):**
```yaml
dataset:
  action_interval: 10    # Alle 10 Frames wird eine H5-Datei gespeichert
                         # 1 = jeder Frame (Standard)
```

### Verhalten

| action_interval | obses.pth | H5-Dateien | Action beschreibt |
|-----------------|-----------|------------|-------------------|
| 1 (Standard)    | 100 Frames | 100 Dateien | 1 Frame |
| 10              | 100 Frames | 10 Dateien  | 10 Frames |
| 50              | 100 Frames | 2 Dateien   | 50 Frames |

**Wichtig:**
- `obses.pth` enthÃ¤lt **immer alle Frames** (fÃ¼r Video-Rekonstruktion)
- H5-Dateien werden **nur alle N Frames** gespeichert
- Die Action beschreibt die **Bewegung Ã¼ber N Frames**

### Action-Format bei action_interval > 1

**"delta_pose" (4D):** Gesamte PositionsÃ¤nderung Ã¼ber N Frames
```
action = [Î£delta_x, Î£delta_y, Î£delta_z, Î£delta_yaw]
```

**"velocity" (4D):** Durchschnittsgeschwindigkeit Ã¼ber N Frames
```
action = [avg_vx, avg_vy, avg_vz, avg_omega_z]
```

**"ee_pos" (6D):** Start- und Endposition des Intervalls
```
action = [x_start, y_start, z_start, x_end, y_end, z_end]
```
- `x/y/z_start`: EE-Position am **Anfang** des Intervalls
- `x/y/z_end`: EE-Position am **Ende** des Intervalls

### Ã„nderungen in data_logger.py

1. **Neuer Parameter**: `action_interval` aus config.yaml
2. **Intervall-Buffer**: Speichert Start-Position und akkumuliert Frames
3. **Neue Methode**: `_save_interval_h5()` - speichert H5 am Ende eines Intervalls
4. **Ãœberarbeitete `log_step()`**:
   - Alle Frames â†’ `observations` (fÃ¼r obses.pth)
   - Am Anfang des Intervalls: Start-Position merken
   - Am Ende des Intervalls: H5 mit Action Ã¼ber N Frames speichern
5. **Ãœberarbeitete `end_episode()`**: Speichert Ã¼brige Frames im Buffer

### Beispiel

Mit `action_interval=10` und 95 Frames:
- `obses.pth`: Shape (95, H, W, C) - alle 95 Frames
- H5-Dateien: 10 Dateien (00.h5 bis 09.h5)
  - 00.h5: Frames 1-10 (Action: EE-Bewegung von Frame 1 bis 10)
  - 01.h5: Frames 11-20
  - ...
  - 09.h5: Frames 91-95 (nur 5 Frames, aber trotzdem gespeichert)

---

## [2026-01-14] - Action-Format: Drei konfigurierbare Modi

### âœ… Drei Action-Modi

Das Action-Format ist jetzt Ã¼ber `action_mode` Parameter (in config.yaml) konfigurierbar:

**Option 1: `action_mode="delta_pose"` (4D)**
```
action = [delta_x, delta_y, delta_z, delta_yaw]
```
- **delta_x/y/z**: Relative Position-Ã„nderung des EE in Metern
- **delta_yaw**: Rotation um Z-Achse in Radiant

**Option 2: `action_mode="velocity"` (4D)**
```
action = [vx, vy, vz, omega_z]
```
- **vx/vy/vz**: Translatorische Geschwindigkeit in m/s
- **omega_z**: Rotatorische Geschwindigkeit um Z-Achse in rad/s

**Option 3: `action_mode="ee_pos"` (6D, wie DINO WM Rope) - DEFAULT**
```
action = [x_start, y_start, z_start, x_end, y_end, z_end]
```
- **x/y/z_start**: EE-Position am Anfang der Bewegung (vorheriger Timestep)
- **x/y/z_end**: EE-Position am Ende der Bewegung (aktueller Timestep)

Diese Option ist analog zum Rope-Format im DINO World Model, wo Actions als
`[start_x, start_z, end_x, end_z]` (2D) codiert sind. FÃ¼r Franka in 3D sind
es entsprechend 6 Dimensionen.

### Ã„nderungen in config.yaml

```yaml
dataset:
  action_mode: "ee_pos"       # Default (6D, wie DINO WM)
  # action_mode: "delta_pose" # Alternative (4D)
  # action_mode: "velocity"   # Alternative (4D)
```

### Ã„nderungen in data_logger.py

1. **Neuer Parameter**: `action_mode` ("delta_pose" oder "velocity")
2. **Parameter**: `dt` fÃ¼r Timestep (Default: 1/60s = 60Hz)
3. **Neue Methoden**:
   - `_quaternion_to_yaw()`: Extrahiert Yaw aus Quaternion
   - `_normalize_angle()`: Normalisiert Winkel auf [-Ï€, Ï€]
4. **Action-Berechnung** automatisch aus EE-Pose:
   ```python
   # delta_pose Modus
   delta_pos = ee_pos - prev_ee_pos
   delta_yaw = current_yaw - prev_yaw
   action = [delta_pos[0], delta_pos[1], delta_pos[2], delta_yaw]
   
   # velocity Modus
   velocity = delta_pos / dt
   omega_z = delta_yaw / dt
   action = [velocity[0], velocity[1], velocity[2], omega_z]
   ```
5. **H5-Info**: `action_mode` wird als Attribut in `info/` gespeichert

### Ã„nderungen in fcs_main_parallel.py

1. **Logger-Initialisierung** liest `action_mode` aus Config:
   ```python
   action_mode = CFG.get("dataset", {}).get("action_mode", "delta_pose")
   logger = FrankaDataLogger(config=CFG, action_mode=action_mode, dt=1.0/60.0)
   ```

### Ã„nderungen in franka_cube_stack_dset.py

1. **Automatische Erkennung** des `action_mode` aus H5-Dateien
2. **Einheitliche Z-Score Normalisierung** fÃ¼r alle 4 Dimensionen
3. **Info-Ausgabe** zeigt erkannten action_mode und Format

### Rope-KompatibilitÃ¤t

Das neue Format ist vollstÃ¤ndig kompatibel mit dem Rope-Dataset:
- `obses.pth`: (T, H, W, C) float32, Werte 0-255
- `action` in H5: (4,) float64
- `eef_states`: (1, 1, 14) float64
- `positions`: (1, n_cubes, 4) float32
- `observations/color/cam_0`: (1, H, W, 3) float32
- `observations/depth/cam_0`: (1, H, W) uint16
- `info/action_mode`: String-Attribut ("delta_pose" oder "velocity")

---

## [2024-XX-XX] - Integration in fcs_main_parallel.py

### âœ… Hauptskript-Anpassungen

#### 1. Logger-Initialisierung
- **Status**: âœ… Angepasst
- **Ã„nderung**: 
  - Alte Signatur: `FrankaDataLogger(save_path=..., object_name=..., ...)`
  - Neue Signatur: `FrankaDataLogger(config=CFG, action_mode="controller")`
  - Dataset-Name wird nachtrÃ¤glich Ã¼berschrieben (fÃ¼r Timestamp-Namen)
- **Zeile**: 625-631

#### 2. Kamera-Kalibrierung
- **Status**: âœ… Implementiert
- **Details**:
  - `logger.set_camera_calibration(intrinsic, extrinsic)` wird aufgerufen
  - `logger.save_camera_calibration()` am Ende
  - Verwendet `env.get_camera_matrices(camera)` fÃ¼r erste Kamera
- **Zeile**: 633-637, 791

#### 3. Daten-Sammlung pro Timestep
- **Status**: âœ… VollstÃ¤ndig angepasst
- **Neue Daten die gesammelt werden**:
  - âœ… RGB-Bilder: `camera.get_rgba()[:, :, :3]`
  - âœ… Depth-Bilder: `camera.get_current_frame()["distance_to_image_plane"]` (mit Fallbacks)
  - âœ… EE-Position: `franka.end_effector.get_world_pose()[0]` (3D)
  - âœ… EE-Quaternion: `franka.end_effector.get_world_pose()[1]` (4D)
  - âœ… WÃ¼rfel-Positionen: Extrahiert aus `task.scene.get_object(cube_name)` mit Yaw-Berechnung
  - âœ… Controller-Action: Direkt Ã¼bergeben
- **Zeile**: 697-740

#### 4. Episode-Buffer-Struktur
- **Status**: âœ… Angepasst
- **Neue Struktur**:
  ```python
  episode_data[i] = {
      "observations": [],      # RGB-Bilder
      "depths": [],            # Depth-Bilder (NEU)
      "ee_positions": [],      # EE-Positionen (NEU)
      "ee_quaternions": [],    # EE-Quaternionen (NEU)
      "cube_positions": [],    # WÃ¼rfel-Positionen (NEU)
      "actions": [],           # Controller-Actions
      "params": {...}
  }
  ```
- **Zeile**: 664-675, 759-770

#### 5. log_step() Aufruf
- **Status**: âœ… VollstÃ¤ndig angepasst
- **Alter Aufruf**:
  ```python
  logger.log_step(rgb_image=obs, state=st, action=act)
  ```
- **Neuer Aufruf**:
  ```python
  logger.log_step(
      rgb_image=obs,
      depth_image=depth,
      ee_pos=ee_pos,
      ee_quat=ee_quat,
      controller_action=controller_act,
      cube_positions=cube_pos
  )
  ```
- **Zeile**: 729-740

#### 6. Yaw-Berechnung fÃ¼r WÃ¼rfel
- **Status**: âœ… Implementiert
- **Details**:
  - Verwendet `scipy.spatial.transform.Rotation`
  - Konvertiert Quaternion â†’ Euler â†’ Yaw (Z-Rotation)
  - Fallback: (0, 0, 0, 0) wenn WÃ¼rfel nicht gefunden
- **Zeile**: 720-730

#### 7. Depth-Bild-API
- **Status**: âœ… Mit Fallbacks implementiert
- **Details**:
  - Versucht `camera.get_current_frame()["distance_to_image_plane"]`
  - Fallback: `camera.get_depth()`
  - Fallback: Leeres Array falls beide fehlschlagen
- **Zeile**: 708-720

#### 8. Property Parameters
- **Status**: âš ï¸ Auskommentiert (wie gewÃ¼nscht)
- **Details**: 
  - `logger.set_episode_params()` ist auskommentiert
  - property_params.pkl wird nicht gespeichert
- **Zeile**: 726

#### 9. Zwischenspeicherung
- **Status**: âœ… Entfernt
- **Details**: 
  - `logger.save_dataset()` wurde entfernt (war fÃ¼r Point Maze Format)
  - Daten werden direkt bei `end_episode()` gespeichert
- **Zeile**: 778-780

### ğŸ”§ Technische Details

#### Neue Imports
- `from pathlib import Path` - FÃ¼r Pfad-Operationen
- `from scipy.spatial.transform import Rotation as R` - FÃ¼r Yaw-Berechnung

#### AbhÃ¤ngigkeiten
- `scipy` ist jetzt erforderlich fÃ¼r Yaw-Berechnung
- Falls nicht verfÃ¼gbar: WÃ¼rfel-Yaw wird auf 0 gesetzt

### ğŸ› Bekannte Probleme / Offene Punkte

1. **Depth-Bild-API**:
   - Die genaue API fÃ¼r Depth-Bilder in Isaac Sim kÃ¶nnte variieren
   - Aktuell mit mehreren Fallbacks implementiert
   - **Status**: Sollte funktionieren, aber kÃ¶nnte optimiert werden

2. **Yaw-Berechnung**:
   - Aktuell: Quaternion â†’ Euler â†’ Yaw
   - KÃ¶nnte direkt aus Quaternion berechnet werden (effizienter)
   - **Status**: Funktioniert, aber kÃ¶nnte optimiert werden

3. **Parallele Umgebungen**:
   - Aktuell: Nur erste Kamera wird fÃ¼r Kalibrierung verwendet
   - Alle Umgebungen verwenden die gleiche Kalibrierung
   - **Status**: Funktioniert, aber kÃ¶nnte pro Env unterschiedlich sein

### ğŸ“ NÃ¤chste Schritte

- [ ] Testen mit echten Daten aus Isaac Sim
- [ ] Validierung der Depth-Bild-API
- [ ] Optimierung der Yaw-Berechnung
- [ ] Optional: Pro-Env Kamera-Kalibrierung

---

## [2024-XX-XX] - Initiale Anpassung fÃ¼r Rope-Format

### ğŸ¯ Ziel
Anpassung des Data Loggers von Point Maze Format auf Rope/D deformable Format fÃ¼r KompatibilitÃ¤t mit bestehenden DatensÃ¤tzen.

### âœ… Implementierte Features

#### 1. Config-Loading aus YAML
- **Status**: âœ… Implementiert
- **Details**: 
  - `load_config_from_yaml()` Funktion hinzugefÃ¼gt
  - LÃ¤dt Konfiguration aus `config.yaml` im gleichen Verzeichnis
  - Extrahiert alle relevanten Parameter (Kamera, WÃ¼rfel, Dataset-Pfade, etc.)
- **Verwendung**: 
  ```python
  config = load_config_from_yaml()
  logger = FrankaDataLogger(config=config)
  ```

#### 2. H5-Dateien pro Timestep
- **Status**: âœ… Implementiert
- **Details**:
  - Jeder Timestep wird als separate H5-Datei gespeichert (`00.h5`, `01.h5`, ...)
  - Dateien werden im Episode-Ordner gespeichert (z.B. `000001/00.h5`)
  - Struktur kompatibel mit Rope-Format
- **Format**: 
  ```
  000001/
  â”œâ”€â”€ obses.pth
  â”œâ”€â”€ 00.h5
  â”œâ”€â”€ 01.h5
  â””â”€â”€ ...
  ```

#### 3. Action-Modi
- **Status**: âœ… Implementiert
- **Details**:
  - **Mode 1: "controller"** (Standard)
    - Verwendet die vom Controller Ã¼bergebene Action
    - Extrahiert Joint-Positions oder Joint-Velocities
    - Format: `(4,) float64`
  - **Mode 2: "ee_velocity"**
    - Berechnet Endeffektor-Position + Velocity
    - Format: `[x, y, z, velocity_magnitude]` (4,) float64
- **Verwendung**:
  ```python
  logger = FrankaDataLogger(config=config, action_mode="controller")
  # oder
  logger = FrankaDataLogger(config=config, action_mode="ee_velocity")
  ```

#### 4. Endeffektor States (eef_states)
- **Status**: âœ… Implementiert
- **Details**:
  - Format: `(1, 1, 14) float64`
  - Struktur: `[[[x, y, z, x, y, z, qw, qx, qy, qz, qw, qx, qy, qz]]]`
  - EnthÃ¤lt: Position (2x dupliziert) + Quaternion (2x dupliziert)
  - Kompatibel mit Rope-Format
- **Speicherung**: In jeder H5-Datei als Dataset `eef_states`

#### 5. WÃ¼rfel-Positionen (positions)
- **Status**: âœ… Implementiert
- **Details**:
  - Format: `(1, n_cubes, 4) float32`
  - FÃ¼r jeden WÃ¼rfel: `(x, y, z, yaw)`
  - Anzahl WÃ¼rfel aus Config geladen (`config["cubes"]["count"]`)
  - Standard: 2 WÃ¼rfel â†’ `(1, 2, 4)`
- **Speicherung**: In jeder H5-Datei als Dataset `positions`

#### 6. Info-Gruppen in H5-Dateien
- **Status**: âœ… Implementiert
- **Details**:
  - `info/n_cams`: `int64` - Anzahl Kameras (1)
  - `info/n_cubes`: `int64` - Anzahl WÃ¼rfel (2)
  - `info/timestamp`: `int64` - Timestep-Nummer
- **Struktur**:
  ```python
  info/
  â”œâ”€â”€ n_cams: 1
  â”œâ”€â”€ n_cubes: 2
  â””â”€â”€ timestamp: 0, 1, 2, ...
  ```

#### 7. Observations in H5-Dateien
- **Status**: âœ… Implementiert
- **Details**:
  - **Color Images**: 
    - Pfad: `observations/color/cam_0`
    - Format: `(1, H, W, 3) float32`
    - Wertebereich: `0-255` (als float32)
    - AuflÃ¶sung: `256Ã—256` (aus Config)
  - **Depth Images**:
    - Pfad: `observations/depth/cam_0`
    - Format: `(1, H, W) uint16`
    - Werte: Tiefenwerte in Millimetern
    - Konvertierung: float32 â†’ uint16 (Ã—1000 fÃ¼r mm)
- **Struktur**:
  ```python
  observations/
  â”œâ”€â”€ color/
  â”‚   â””â”€â”€ cam_0: (1, 256, 256, 3) float32
  â””â”€â”€ depth/
      â””â”€â”€ cam_0: (1, 256, 256) uint16
  ```

#### 8. obses.pth Format
- **Status**: âœ… Implementiert
- **Details**:
  - Format: `(T, H, W, C) uint8`
  - EnthÃ¤lt alle RGB-Bilder einer Episode
  - Gespeichert im Episode-Ordner: `000001/obses.pth`
  - Kompatibel mit Rope-Format
- **Beispiel**: Bei 950 Timesteps â†’ `(950, 256, 256, 3) uint8`

#### 9. Kamera-Kalibrierung
- **Status**: âœ… Implementiert
- **Details**:
  - **Intrinsic**: `(4, 4) float64` - Intrinsische Parameter
  - **Extrinsic**: `(4, 4, 4) float64` - Extrinsische Parameter (4x fÃ¼r KompatibilitÃ¤t, obwohl nur 1 Kamera)
  - Gespeichert in: `cameras/intrinsic.npy` und `cameras/extrinsic.npy`
  - Kamera-Parameter aus Config geladen

#### 10. Property Parameters
- **Status**: âš ï¸ Weggelassen (wie gewÃ¼nscht)
- **Details**: 
  - `property_params.pkl` wird NICHT gespeichert
  - Kann spÃ¤ter hinzugefÃ¼gt werden falls benÃ¶tigt

### ğŸ“‹ Datenstruktur

#### Episode-Ordner
```
dataset_name/
â”œâ”€â”€ cameras/
â”‚   â”œâ”€â”€ intrinsic.npy      # (4, 4) float64
â”‚   â””â”€â”€ extrinsic.npy      # (4, 4, 4) float64
â””â”€â”€ 000001/                 # Episode 1
    â”œâ”€â”€ obses.pth          # (T, 256, 256, 3) uint8
    â”œâ”€â”€ 00.h5              # Timestep 0
    â”œâ”€â”€ 01.h5              # Timestep 1
    â””â”€â”€ ...
```

#### H5-Datei-Struktur (pro Timestep)
```python
00.h5
â”œâ”€â”€ action: (4,) float64
â”œâ”€â”€ eef_states: (1, 1, 14) float64
â”œâ”€â”€ positions: (1, 2, 4) float32
â”œâ”€â”€ info/
â”‚   â”œâ”€â”€ n_cams: int64 (1)
â”‚   â”œâ”€â”€ n_cubes: int64 (2)
â”‚   â””â”€â”€ timestamp: int64
â””â”€â”€ observations/
    â”œâ”€â”€ color/
    â”‚   â””â”€â”€ cam_0: (1, 256, 256, 3) float32
    â””â”€â”€ depth/
        â””â”€â”€ cam_0: (1, 256, 256) uint16
```

### ğŸ”§ Technische Details

#### AbhÃ¤ngigkeiten
- `torch`: FÃ¼r `obses.pth` Speicherung
- `h5py`: **Erforderlich** fÃ¼r H5-Dateien
- `numpy`: FÃ¼r alle Array-Operationen
- `yaml`: FÃ¼r Config-Loading
- `PIL`: Optional fÃ¼r Bild-Resizing

#### Config-Parameter verwendet
- `dataset.path`: Speicherpfad
- `dataset.name`: Datensatz-Name
- `camera.resolution`: BildauflÃ¶sung `[256, 256]`
- `camera.position`: Kamera-Position
- `camera.euler`: Kamera-Orientierung
- `cubes.count`: Anzahl WÃ¼rfel (2)

### ğŸ› Bekannte Probleme / Offene Punkte

1. **Extrinsic-Format**: 
   - Aktuell: `(4, 4, 4)` fÃ¼r 1 Kamera (4x dupliziert fÃ¼r KompatibilitÃ¤t)
   - MÃ¶glicherweise sollte es `(1, 4, 4)` sein
   - **Status**: Funktioniert, aber Format kÃ¶nnte optimiert werden

2. **EE-Velocity-Berechnung**:
   - Aktuell: Delta-Position (ohne dt)
   - Sollte eigentlich durch dt geteilt werden
   - **Status**: Funktioniert, aber kÃ¶nnte prÃ¤ziser sein

3. **Action-Extraktion**:
   - Aktuell: Nimmt erste 4 Joints
   - KÃ¶nnte spezifischer sein je nach Controller-Typ
   - **Status**: Funktioniert, aber kÃ¶nnte verbessert werden

4. **Timestep-Limit**:
   - User erwÃ¤hnt ~950 Timesteps, mÃ¶glicherweise zu reduzieren
   - **Status**: Kein Limit implementiert, kann in Config hinzugefÃ¼gt werden

### ğŸ“ NÃ¤chste Schritte

- [ ] Testen mit echten Daten aus Isaac Sim
- [ ] Validierung der H5-Struktur gegen Rope-Datensatz
- [ ] Optimierung der Action-Extraktion
- [ ] PrÃ¤zisere Velocity-Berechnung (mit dt)
- [ ] Optional: property_params.pkl wieder hinzufÃ¼gen falls benÃ¶tigt
- [ ] Dokumentation der Verwendung im Haupt-Skript

### ğŸ”„ Migration von Point Maze Format

#### Alte Struktur (Point Maze):
```
dataset/
â”œâ”€â”€ states.pth
â”œâ”€â”€ actions.pth
â”œâ”€â”€ seq_lengths.pth
â””â”€â”€ obses/
    â””â”€â”€ episode_XXX.pth
```

#### Neue Struktur (Rope):
```
dataset/
â”œâ”€â”€ cameras/
â”‚   â”œâ”€â”€ intrinsic.npy
â”‚   â””â”€â”€ extrinsic.npy
â””â”€â”€ 000001/
    â”œâ”€â”€ obses.pth
    â””â”€â”€ XX.h5 (pro Timestep)
```

### ğŸ“Š Vergleich mit Rope-Format

| Feature | Rope-Format | Unser Format | Status |
|---------|-------------|--------------|--------|
| obses.pth | âœ… (T, H, W, C) | âœ… (T, H, W, C) | âœ… Kompatibel |
| H5 pro Timestep | âœ… | âœ… | âœ… Kompatibel |
| action | âœ… (4,) | âœ… (4,) | âœ… Kompatibel |
| eef_states | âœ… (1, 1, 14) | âœ… (1, 1, 14) | âœ… Kompatibel |
| positions | âœ… (1, 1965, 4) | âœ… (1, 2, 4) | âœ… Kompatibel (2 WÃ¼rfel) |
| info/n_cams | âœ… | âœ… | âœ… Kompatibel |
| info/n_particles | âœ… | âŒ (n_cubes statt n_particles) | âš ï¸ Unterschiedlich |
| observations/color | âœ… | âœ… | âœ… Kompatibel |
| observations/depth | âœ… | âœ… | âœ… Kompatibel |
| cameras/intrinsic | âœ… (4, 4) | âœ… (4, 4) | âœ… Kompatibel |
| cameras/extrinsic | âœ… (4, 4, 4) | âœ… (4, 4, 4) | âœ… Kompatibel |

### ğŸ“ Lektionen gelernt

1. **H5-Format**: Sehr flexibel, aber Struktur muss exakt eingehalten werden
2. **Config-Loading**: YAML macht Konfiguration viel einfacher
3. **Action-Modi**: FlexibilitÃ¤t wichtig fÃ¼r verschiedene AnwendungsfÃ¤lle
4. **KompatibilitÃ¤t**: Rope-Format hat spezifische Anforderungen (z.B. duplizierte Werte in eef_states)

---

## Versionen

- **v1.0.0** (2024-XX-XX): Initiale Anpassung fÃ¼r Rope-Format

